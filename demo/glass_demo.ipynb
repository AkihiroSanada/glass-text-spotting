{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wjIJwQc1r2uB"
   },
   "source": [
    "# GLASS Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJiyXVYmr2uC"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from glass.inference.glass_runner import GlassRunner\n",
    "from glass.utils.logger import setup_logger\n",
    "from glass.utils.visualizer import visualize\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxF-W1Bfr2uD"
   },
   "outputs": [],
   "source": [
    "#@ Installing Detectron2 and PyYaml which are prerequisite\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!python -m pip install -U PyYAML\n",
    "\n",
    "#@ Install GLASS\n",
    "!git clone 'https://github.com/amazon-science/glass-text-spotting'\n",
    "%cd glass-text-spotting\n",
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJ87b0Fxr2uE"
   },
   "outputs": [],
   "source": [
    "#@ Download the pretrained TextOCR model\n",
    "!mkdir assets\n",
    "!wget 'https://glass-text-spotting.s3.eu-west-1.amazonaws.com/models/glass_250k_full_textocr_finetune.pth' -O 'assets/glass_textocr.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting up the runner for running inference. The runner also includes the text encoder\n",
    "model_path = 'assets/glass_textocr.pth'\n",
    "config_path = '/hiero_efs/HieroUsers/tsiper/HieroDeploy/TextractGlassOCR/configs/glass_finetune_textocr.yaml'\n",
    "glass_runner = GlassRunner(model_path=model_path, config_path=config_path, post_process=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0tXNUPcr2uF"
   },
   "outputs": [],
   "source": [
    "#@ Choose an image\n",
    "image_id = 3  #@param {type:\"slider\", min:1, max:4, step:1}\n",
    "image_url = f'https://raw.githubusercontent.com/Yuliang-Liu/Curve-Text-Detector/master/images/demo/{image_id}.jpg'\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown Or provide a url path to cropped text image (Optional).\n",
    "#@markdown ### Enter a file path:\n",
    "\n",
    "file_path = \"\"  #@param {type:\"string\"}\n",
    "if file_path:\n",
    "    image_url = file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xKqMtalr2uF"
   },
   "outputs": [],
   "source": [
    "# Obtaining the image:\n",
    "file_name, headers = urllib.request.urlretrieve(image_url)\n",
    "image = np.asarray(Image.open(file_name).convert('RGB')) # Inference is not supported for images with alpha channel\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4s-M4U2xr2uG"
   },
   "outputs": [],
   "source": [
    "# Running GLASS on the input image\n",
    "preds = glass_runner(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing the results, hover on the detections for viewing the confidence\n",
    "figure = visualize(preds=preds, image=image, text_encoder=glass_runner.text_encoder, vis_width=720, vis_text=True)\n",
    "figure.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
